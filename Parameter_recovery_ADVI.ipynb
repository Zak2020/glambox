{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/felixmolter/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "import glam\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Systematic parameter recovery (ADVI)\n",
    "\n",
    "Here, we perform a structured and systematic parameter recovery study. We use the original model variant with 4 parameters ($v$, $\\gamma$, $\\sigma$, $\\tau$). For each parameter, we define a range of sensible values and select a `low`, `medium` and `high` value, based on the individual parameter estimates we obtained by hierarchically fitting the GLAM to the data from Krajbich & Rangel (2011) in Thomas, Molter, Krajbich, Heekeren & Mohr (submitted).\n",
    "\n",
    "We then pick one parameter, one constellation of values of the remaining three parameters (e.g., we pick $v$, and set $\\gamma$, $\\sigma$ and $\\tau$ to their `low` values). Then, for 10 different values of $v$ along its range, we generate a synthetic dataset for a single participant with N=100 trials, random item values and gaze, fit the model and record the generating and estimated parameters. The procedure is repeated for all possible constellation of other parameter values, and other parameters, resulting in 1080 ($10 \\times 4 \\times 3^3$) simulated and fitted datasets total."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define parameter ranges from 2011 estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'v': array([1.50e-05, 3.00e-05, 4.50e-05, 6.00e-05, 7.50e-05, 9.00e-05,\n",
       "        1.05e-04, 1.20e-04, 1.35e-04, 1.50e-04]),\n",
       " 'gamma': array([-1.        , -0.77777778, -0.55555556, -0.33333333, -0.11111111,\n",
       "         0.11111111,  0.33333333,  0.55555556,  0.77777778,  1.        ]),\n",
       " 's': array([0.004     , 0.00477778, 0.00555556, 0.00633333, 0.00711111,\n",
       "        0.00788889, 0.00866667, 0.00944444, 0.01022222, 0.011     ]),\n",
       " 'tau': array([0.1       , 0.22777778, 0.35555556, 0.48333333, 0.61111111,\n",
       "        0.73888889, 0.86666667, 0.99444444, 1.12222222, 1.25      ])}"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bounds = dict(v=[0.000015, 0.00015],\n",
    "              gamma=[-1, 1],\n",
    "              s=[0.004, 0.011],\n",
    "              tau=[0.1, 1.25])\n",
    "\n",
    "ranges = {parameter: np.linspace(*bounds[parameter], 10)\n",
    "          for parameter in ['v', 'gamma', 's', 'tau']}\n",
    "ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'v': array([2.850e-05, 8.250e-05, 1.365e-04]),\n",
       " 'gamma': array([-8.00000000e-01,  5.55111512e-17,  8.00000000e-01]),\n",
       " 's': array([0.0047, 0.0075, 0.0103]),\n",
       " 'tau': array([0.215, 0.675, 1.135])}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Determine low, medium, high values as 10th, 50th and 90th percentile of these ranges\n",
    "values = {parameter: np.percentile(np.linspace(*bounds[parameter], 100), [10, 50, 90])\n",
    "          for parameter in ['v', 'gamma', 's', 'tau']}\n",
    "values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recover a single GLAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recover_glam(parameters, n_trials=100, n_items=3, seed=None):\n",
    "\n",
    "    G = glam.GLAM()\n",
    "\n",
    "    G.simulate_group(kind='individual',\n",
    "                     n_individuals=1,\n",
    "                     n_trials=n_trials, \n",
    "                     n_items=n_items,\n",
    "                     parameters=parameters,\n",
    "                     error_weight=0,\n",
    "                     value_range=[1, 10],\n",
    "                     seed=seed)\n",
    "    G.make_model('individual', t0_val=0, error_weight=0)\n",
    "    G.fit(method='VI', n_samples=2000, n_vi=50000, progressbar=False)\n",
    "    \n",
    "    return G"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating single subject models for 1 subjects...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING (theano.gof.cmodule): Deleting (broken cache directory [EOF]): /Users/felixmolter/.theano/compiledir_Darwin-17.7.0-x86_64-i386-64bit-i386-3.6.5-64/tmp5qkc5ie2\n",
      "INFO (theano.gof.compilelock): Waiting for existing lock by process '35413' (I am process '36753')\n",
      "INFO (theano.gof.compilelock): To manually release the lock, delete /Users/felixmolter/.theano/compiledir_Darwin-17.7.0-x86_64-i386-64bit-i386-3.6.5-64/lock_dir\n",
      "INFO (theano.gof.compilelock): Waiting for existing lock by process '35314' (I am process '36753')\n",
      "INFO (theano.gof.compilelock): To manually release the lock, delete /Users/felixmolter/.theano/compiledir_Darwin-17.7.0-x86_64-i386-64bit-i386-3.6.5-64/lock_dir\n",
      "INFO (theano.gof.compilelock): Waiting for existing lock by process '35414' (I am process '36753')\n",
      "INFO (theano.gof.compilelock): To manually release the lock, delete /Users/felixmolter/.theano/compiledir_Darwin-17.7.0-x86_64-i386-64bit-i386-3.6.5-64/lock_dir\n"
     ]
    }
   ],
   "source": [
    "parameters = dict(v=[ranges['v'][0]],\n",
    "                  gamma=[values['gamma'][0]],\n",
    "                  s=[values['s'][0]],\n",
    "                  tau=[values['tau'][0]],\n",
    "                  t0=[0])\n",
    "\n",
    "result = recover_glam(parameters=parameters, seed=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run over multiple parameter sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_info = {parameter: dict(low=values[parameter][0],\n",
    "                                  medium=values[parameter][1],\n",
    "                                  high=values[parameter][2],\n",
    "                                  variable=ranges[parameter])\n",
    "                  for parameter in ['v', 'gamma', 's', 'tau']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def generate_parameter_sets(parameter_info):\n",
    "\n",
    "    from itertools import product\n",
    "    \n",
    "    levels = ['low', 'medium', 'high']\n",
    "    parameters = ['v', 'gamma', 's', 'tau']\n",
    "    \n",
    "    constellations = list(product(levels, levels, levels))\n",
    "\n",
    "    index = 0\n",
    "    \n",
    "    for variable_parameter in parameter_info.keys():\n",
    "        \n",
    "        others = [p for p in parameters\n",
    "                  if p != variable_parameter]\n",
    "        \n",
    "        for other_constellation in constellations:\n",
    "\n",
    "            for variable_value in parameter_info[variable_parameter]['variable']:\n",
    "\n",
    "                level_set = dict()\n",
    "                level_set[variable_parameter] = 'variable'\n",
    "                parameter_set = dict(t0=[0])\n",
    "                parameter_set[variable_parameter] = [variable_value]\n",
    "\n",
    "                for o, other in enumerate(others):\n",
    "                    level_set[other] = other_constellation[o]\n",
    "                    parameter_set[other] = [parameter_info[other][other_constellation[o]]]\n",
    "                    \n",
    "                index += 1\n",
    "                yield index, level_set, parameter_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_generated_inputs = list(generate_parameter_sets(parameter_info=parameter_info))\n",
    "all_generated_inputs[:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir results/parameter_recovery\n",
    "!mkdir results/parameter_recovery/advi\n",
    "!mkdir results/parameter_recovery/advi/partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import join, isfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrap_recover_glam(generated_input):\n",
    "    \n",
    "    from pymc3 import summary\n",
    "    \n",
    "    index, level_set, parameter_set = generated_input\n",
    "\n",
    "    # check if already done:\n",
    "    filename = join('results', 'parameter_recovery', 'advi', 'partial', 'parameter_recovery_advi_part{}.csv'.format(index))\n",
    "    if isfile(filename):\n",
    "        print(\"Found previous result for index {}. Skipping...\".format(index))\n",
    "        return\n",
    "    else:\n",
    "        # perform actual recovery\n",
    "        result = recover_glam(parameter_set, n_trials=100, n_items=3, seed=index)\n",
    "\n",
    "        # assemble output dataframe row\n",
    "        output = pd.DataFrame(dict(index=[index],\n",
    "                                   v_level=[level_set['v']],\n",
    "                                   gamma_level=[level_set['gamma']],\n",
    "                                   s_level=[level_set['s']],\n",
    "                                   tau_level=[level_set['tau']],\n",
    "                                   v_gen=parameter_set['v'],\n",
    "                                   gamma_gen=parameter_set['gamma'],\n",
    "                                   s_gen=parameter_set['s'],\n",
    "                                   tau_gen=parameter_set['tau'],\n",
    "                                   v_rec=result.estimates['v'][0],\n",
    "                                   gamma_rec=result.estimates['gamma'][0],\n",
    "                                   s_rec=result.estimates['s'][0],\n",
    "                                   tau_rec=result.estimates['tau'][0],\n",
    "                                   converged=[np.nan]))\n",
    "\n",
    "        output.to_csv(filename,\n",
    "                      index=False)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrap_recover_glam(all_generated_inputs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run the recovery in parallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "\n",
    "n_cores = 4\n",
    "p = Pool(n_cores)\n",
    "\n",
    "output = p.map(wrap_recover_glam, generate_parameter_sets(parameter_info))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = [file for file in listdir(join('results', 'parameter_recovery', 'advi', 'partial'))\n",
    "             if file.endswith('.csv')]\n",
    "\n",
    "partial_recoveries = []\n",
    "\n",
    "for file in filenames:\n",
    "    partial = pd.read_csv(join('results', 'parameter_recovery', 'advi', 'partial', filename))\n",
    "    partial_recoveries.append(partial)\n",
    "\n",
    "parameter_recovery = pd.concat(partial_recoveries).sort_values(index).reset_index(drop=True)\n",
    "del partial_recoveries\n",
    "parameter_recovery.to_csv(join('results', 'parameter_recovery', 'advi', 'parameter_recovery_advi.csv'))\n",
    "parameter_recovery.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plot results\n",
    "\n",
    "The above analysis was performed on a different multicore machine. We therefore load its results here:"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "recovery_df = pd.read_csv('/Users/felixmolter/Dropbox/recovery_partial.csv')\n",
    "print('P(converged):', recovery_df['converged'].mean())\n",
    "recovery_df = recovery_df[recovery_df['converged'] == True].copy()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def format_p(p):\n",
    "    \"\"\"\n",
    "    Format a p-value to a string with some cutoffs.\n",
    "    \"\"\"\n",
    "    if p < 0.00001:\n",
    "        return r'$P$ < 0.00001'\n",
    "    elif p < 0.0001:\n",
    "        return r'$P$ < 0.0001'\n",
    "    else:\n",
    "        return r'$P$ = {:.4f}'.format(p)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def plot_recovery_panel(recovery_df, variable, other_levels, ax=None, ci=0.95):\n",
    "    \n",
    "    import statsmodels.api as sm\n",
    "    from statsmodels.stats.outliers_influence import summary_table\n",
    "    \n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots()\n",
    "    \n",
    "    # Subset data\n",
    "    df = recovery_df[(recovery_df['{}_level'.format(variable)] == 'variable')]\n",
    "    for parameter, level in other_levels.items():\n",
    "        df = df[df['{}_level'.format(parameter)] == level].copy()\n",
    "    \n",
    "    gen = df['{}_gen'.format(variable)].values\n",
    "    rec = df['{}_rec'.format(variable)].values\n",
    "\n",
    "    mini = np.stack([gen, rec]).min()\n",
    "    maxi = np.stack([gen, rec]).max()\n",
    "    diff = maxi - mini\n",
    "    \n",
    "    minilim = mini - 0.1 * diff\n",
    "    maxilim = maxi + 0.1 * diff\n",
    "    \n",
    "    ax.scatter(gen,\n",
    "               rec,\n",
    "               color='lightgray',\n",
    "               edgecolor='k',\n",
    "               linewidth=1,\n",
    "               alpha=0.9)\n",
    "    \n",
    "    ax.set_xlim(minilim, maxilim)\n",
    "    ax.set_ylim(minilim, maxilim)\n",
    "\n",
    "    # Linear model fit\n",
    "    X = sm.add_constant(gen)\n",
    "    lm = sm.OLS(rec, X).fit()\n",
    "    intercept, slope = lm.params\n",
    "    table, data, columns = summary_table(lm, alpha=1.-ci)\n",
    "    predicted, mean_ci_lower, mean_ci_upper = data[:, np.array([2, 4, 5])].T\n",
    "\n",
    "    tval = lm.tvalues[-1]\n",
    "    pval = lm.pvalues[-1]\n",
    "    \n",
    "    xs = np.linspace(*ax.get_xlim(), 100)\n",
    "    ax.plot(xs, intercept + slope * xs,\n",
    "                color='deeppink', zorder=-8)\n",
    "    sort_idx = np.argsort(gen)\n",
    "    ax.fill_between(gen[sort_idx], mean_ci_lower[sort_idx], mean_ci_upper[sort_idx],\n",
    "                    color='deeppink', alpha=0.1, zorder=-8)\n",
    "    \n",
    "    p_string = format_p(pval)\n",
    "    beta_annotation = [r'$\\beta_{}$ = {:.4f}'.format(b, beta)\n",
    "                       for b, beta in enumerate(lm.params)]\n",
    "    \n",
    "    annotation = '\\n'.join(beta_annotation) + '\\n' + r'$t$ = {:.2f}'.format(tval) + '\\n' + p_string\n",
    "    ax.text(0.1,\n",
    "            0.9,\n",
    "            annotation,\n",
    "            verticalalignment='top',\n",
    "            transform=ax.transAxes,\n",
    "            fontsize='small')\n",
    "    \n",
    "    ax.plot(ax.get_xlim(), ax.get_ylim(),\n",
    "            linewidth=0.25,\n",
    "            color='k', alpha=0.9, zorder=-9)\n",
    "    \n",
    "    ax.set_xlabel('Generating')\n",
    "    ax.set_ylabel('Recovered')\n",
    "    \n",
    "    return ax"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Example of a plot of a single recovery panel\n",
    "# specify other (background) parameters levels\n",
    "other_levels = dict(tau='high', s='medium', gamma='low')\n",
    "ax = plot_recovery_panel(recovery_df, variable='v', other_levels=other_levels)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def plot_recovery(recovery_df,\n",
    "                  variables=['v', 'gamma', 's', 'tau'],\n",
    "                  levels=['low', 'medium', 'high'],\n",
    "                  bounds=dict(v=[0.000015, 0.00015],\n",
    "                              gamma=[-1, 1],\n",
    "                              s=[0.004, 0.011],\n",
    "                              tau=[0.1, 1.25])):\n",
    "    \"\"\"\n",
    "    Plots a single axes containing the relationship between\n",
    "    generating and recovered values of the indicated `variable`,\n",
    "    keeping all other parameters at their respective levels\n",
    "    specified in the `other_levels` dictionary.\n",
    "    \"\"\"\n",
    "    from itertools import product\n",
    "    \n",
    "    n_rows = len(variables)\n",
    "    n_cols = (len(levels))**(len(variables)-1)\n",
    "    \n",
    "    fig, axs = plt.subplots(n_rows, n_cols,\n",
    "                            figsize=(n_cols*3, n_rows*3),\n",
    "                            sharey='row',\n",
    "                            sharex='row')\n",
    "\n",
    "    for i, var in enumerate(variables):\n",
    "        others = [v for v in variables\n",
    "                  if v != var]\n",
    "        n_others = len(others)\n",
    "        \n",
    "        if n_others == 1:            \n",
    "            constellations = list(product(levels))\n",
    "        elif n_others == 2:\n",
    "            constellations = list(product(levels, levels))\n",
    "        elif n_others == 3:\n",
    "            constellations = list(product(levels, levels, levels))\n",
    "        else:\n",
    "            ValueError('What?!')\n",
    "\n",
    "        for j, constellation in enumerate(constellations):\n",
    "            other_levels = {other: constellation[o]\n",
    "                            for o, other in enumerate(others)}\n",
    "            try: \n",
    "                axs[i, j] = plot_recovery_panel(recovery_df, variable=var, other_levels=other_levels, ax=axs[i, j])\n",
    "            except:\n",
    "                continue\n",
    "            axs[i, j].set_title('')\n",
    "            axs[i, j].set_xlabel('')\n",
    "            axs[i, j].set_ylabel('')\n",
    "            title = ['{}: {}, '.format(other, level)\n",
    "                     for other, level in other_levels.items()]\n",
    "            axs[i, j].set_title(''.join(title))\n",
    "            axs[i, j].set_xlim(*bounds[var])\n",
    "            axs[i, j].set_ylim(*bounds[var])\n",
    "            \n",
    "        axs[i, 0].set_ylabel('{}\\nRecovered'.format(var))\n",
    "    \n",
    "    for ax in axs[-1, :]:\n",
    "        ax.set_xlabel('Generating')\n",
    "    \n",
    "    fig.tight_layout()\n",
    "    \n",
    "    return fig, axs"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "recovery_df = pd.read_csv('/Users/felixmolter/Dropbox/recovery_partial.csv')\n",
    "print('P(converged):', recovery_df['converged'].mean())\n",
    "recovery_df = recovery_df[recovery_df['converged'] == True].copy()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "plot_recovery(recovery_df=recovery_df, variables=['tau', 'v', 's']);\n",
    "plt.savefig('/Users/felixmolter/Desktop/recovery_converged_3.png', dpi=300)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "120px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
